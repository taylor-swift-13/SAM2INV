"""
å¾ªçŽ¯ä¸å˜é‡ç”Ÿæˆä¸»ç¨‹åº
æ•´åˆé‡‡æ ·ã€ç”Ÿæˆã€éªŒè¯å’Œè¿­ä»£ä¿®å¤

ä½¿ç”¨æ–¹æ³•:
    python3 loop_inv.py 2
"""
import argparse
import logging
import os
import signal
import sys
import time
from inv_generator import InvariantGenerator
from llm import LLMConfig, reset_token_stats, get_token_stats
from config import SUBDIR, MAX_ITERATION

# é…ç½®ï¼šinput å­ç›®å½•ï¼ˆå•ä¸€å…¥å£ï¼‰
INPUT_SUBDIR = SUBDIR  # é»˜è®¤å€¼ï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

def setup_logger(file_name: str, log_dir: str = None) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨ï¼Œå°†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶å’ŒæŽ§åˆ¶å°
    æ—¥å¿—ç›®å½•ä¼šè‡ªåŠ¨ä¸Ž input/output ç»“æž„å¯¹é½
    
    Args:
        file_name: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        log_dir: æ—¥å¿—ç›®å½•ï¼ˆå¦‚æžœä¸º Noneï¼Œåˆ™è‡ªåŠ¨å¯¹é½ input è·¯å¾„ï¼‰
        
    Returns:
        é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    # å¦‚æžœæœªæŒ‡å®š log_dirï¼Œåˆ™æŒ‰å…¨å±€ subdir è‡ªåŠ¨å¯¹é½
    if log_dir is None:
        log_dir = os.path.join("log", INPUT_SUBDIR)
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = logging.getLogger('SE2INV')
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨
    # Remove .c extension if present to avoid duplicate extension in log filename
    log_file_name = file_name[:-2] if file_name.endswith('.c') else file_name
    log_file_path = os.path.join(log_dir, f'{log_file_name}.log')
    file_handler = logging.FileHandler(log_file_path, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)
    
    # æŽ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    return logger

def main():
    global INPUT_SUBDIR
    parser = argparse.ArgumentParser(
        description="ç”Ÿæˆå¾ªçŽ¯ä¸å˜é‡ï¼ˆåŒ…å«è¿­ä»£ä¿®å¤ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python3 loop_inv.py 2
        """
    )
    parser.add_argument('file_name', type=str, help="æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰")
    parser.add_argument('--input-subdir', type=str, default=INPUT_SUBDIR, help=f"input å­ç›®å½•ï¼ˆé»˜è®¤: {INPUT_SUBDIR}ï¼‰")
    parser.add_argument('--output-dir', type=str, default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤æŒ‰é…ç½®è‡ªåŠ¨ç”Ÿæˆï¼‰")
    parser.add_argument('--log-dir', type=str, default=None, help="æ—¥å¿—ç›®å½•ï¼ˆé»˜è®¤è‡ªåŠ¨å¯¹é½ input è·¯å¾„ï¼‰")
    parser.add_argument('--max-iterations', type=int, default=MAX_ITERATION, help="æœ€å¤§è¿­ä»£ä¿®å¤æ¬¡æ•°")
    
    args = parser.parse_args()
    INPUT_SUBDIR = args.input_subdir  # æ›´æ–°å…¨å±€é…ç½®
    
    # é‡ç½® token ç»Ÿè®¡ï¼ˆå¼€å§‹æ–°çš„åˆ†æžæ—¶ï¼‰
    reset_token_stats()
    
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨ï¼ˆè‡ªåŠ¨å¯¹é½ input è·¯å¾„ï¼‰
    logger = setup_logger(args.file_name, log_dir=args.log_dir)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # åˆ›å»ºä¸å˜é‡ç”Ÿæˆå™¨ï¼ˆä¼ å…¥ input_subdir é…ç½®ï¼‰
    generator = InvariantGenerator(args.file_name, LLMConfig(), logger, input_subdir=INPUT_SUBDIR)
    
    # è®¾ç½®æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆä»…åœ¨ repairer å­˜åœ¨æ—¶ï¼‰
    if generator.repairer is not None:
        generator.repairer.max_iterations = args.max_iterations
    
    # Register SIGTERM handler to save partial results on timeout
    def _sigterm_handler(signum, frame):
        logger.warning("Received SIGTERM (timeout), saving partial results...")
        generator.save_results(args.output_dir)
        # Log partial first_pass if available
        first_pass = generator.first_pass if hasattr(generator, 'first_pass') and generator.first_pass else None
        if first_pass:
            logger.info(f"syntax={first_pass.get('syntax', 'N/A')}, valid={first_pass.get('valid', 'N/A')}, satisfy={first_pass.get('satisfy', 'N/A')}")
        total_duration = time.time() - start_time
        logger.info(f"Total execution time before timeout: {total_duration:.2f} seconds")
        stats = get_token_stats()
        logger.info(f"Total API calls: {stats['call_count']}, Total tokens: {stats['total_tokens']:,}")
        sys.exit(1)

    signal.signal(signal.SIGTERM, _sigterm_handler)

    logger.info(f"å¼€å§‹ä¸º {args.file_name} ç”Ÿæˆå¾ªçŽ¯ä¸å˜é‡...")
    annotated_code = generator.generate_all(max_iterations=args.max_iterations)
    
    # è®°å½•ç»“æŸæ—¶é—´
    end_time = time.time()
    total_duration = end_time - start_time
    
    # èŽ·å–å¹¶è¾“å‡º token ç»Ÿè®¡ä¿¡æ¯
    token_stats = get_token_stats()
    logger.info("=" * 60)
    logger.info("Token ä½¿ç”¨ç»Ÿè®¡:")
    logger.info(f"  æ€»è°ƒç”¨æ¬¡æ•°: {token_stats['call_count']}")
    logger.info(f"  Prompt Tokens: {token_stats['total_prompt_tokens']:,}")
    logger.info(f"  Completion Tokens: {token_stats['total_completion_tokens']:,}")
    logger.info(f"  æ€» Tokens: {token_stats['total_tokens']:,}")
    if token_stats['call_count'] > 0:
        avg_prompt = token_stats['total_prompt_tokens'] / token_stats['call_count']
        avg_completion = token_stats['total_completion_tokens'] / token_stats['call_count']
        avg_total = token_stats['total_tokens'] / token_stats['call_count']
        logger.info(f"  å¹³å‡æ¯æ¬¡è°ƒç”¨:")
        logger.info(f"    Prompt: {avg_prompt:.1f} tokens")
        logger.info(f"    Completion: {avg_completion:.1f} tokens")
        logger.info(f"    æ€»è®¡: {avg_total:.1f} tokens")
    logger.info("=" * 60)
    
    # Always save results, even if generation failed
    generator.save_results(args.output_dir)
    
    if annotated_code:
        logger.info(f"å®Œæˆï¼å·²ç”ŸæˆåŒ…å«ä¸å˜é‡çš„å®Œæ•´ C ä»£ç ")
    else:
        logger.error("ç”Ÿæˆå¤±è´¥ï¼šæ— æ³•ç”Ÿæˆå¾ªçŽ¯ä¸å˜é‡ï¼Œå·²ä¿å­˜åŽŸå§‹è¾“å…¥æ–‡ä»¶")
    
    # è®°å½• first_pass æŒ‡æ ‡
    first_pass = generator.first_pass if hasattr(generator, 'first_pass') and generator.first_pass else None
    if first_pass:
        logger.info("="*50)
        logger.info("first_pass:")
        logger.info(f"syntax={first_pass.get('syntax', 'N/A')}, valid={first_pass.get('valid', 'N/A')}, satisfy={first_pass.get('satisfy', 'N/A')}")
        logger.info("="*50)
    
    # è®°å½•æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
    logger.info("="*50)
    logger.info("â° OVERALL EXECUTION TIME STATISTICS")
    logger.info(f"Total execution time: {total_duration:.2f} seconds ({total_duration/60:.2f} minutes)")
    logger.info("="*50)
    
    # è®°å½• token ä½¿ç”¨ç»Ÿè®¡
    stats = get_token_stats()
    logger.info("="*50)
    logger.info("ðŸ“Š TOKEN USAGE STATISTICS")
    logger.info(f"Total API calls: {stats['call_count']}")
    logger.info(f"Total prompt tokens (input): {stats['total_prompt_tokens']:,}")
    logger.info(f"Total completion tokens (output): {stats['total_completion_tokens']:,}")
    logger.info(f"Total tokens: {stats['total_tokens']:,}")
    if stats['call_count'] > 0:
        avg_prompt = stats['total_prompt_tokens'] / stats['call_count']
        avg_completion = stats['total_completion_tokens'] / stats['call_count']
        avg_total = stats['total_tokens'] / stats['call_count']
        logger.info(f"Average prompt tokens per call: {avg_prompt:.1f}")
        logger.info(f"Average completion tokens per call: {avg_completion:.1f}")
        logger.info(f"Average total tokens per call: {avg_total:.1f}")
    logger.info("="*50)

if __name__ == "__main__":
    main()
