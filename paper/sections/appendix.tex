%% ============================================================
\appendix
%% ============================================================

%% ============================================================
\section{\textsc{LoopFactory} DSL: Sampling Procedure and Concrete Example}
\label{app:loop-factory}
%% ============================================================

\subsection{Full Generation Procedure}

Algorithm~\ref{alg:loop-factory} shows the complete \textsc{LoopFactory}
generation loop.
Starting from a drawn hyperparameter vector~$\theta$ (or a fixed
configuration), the factory (i)~selects parameters from a candidate pool,
(ii)~samples loop count and, for each loop, the NLA vs.\ linear
family classification, (iii)~allocates fresh single-letter variable names
for each loop's counter and limit, (iv)~samples loop control modes
(increment, decrement, multiplicative, distance-to-limit, etc.),
(v)~fills each loop body with self-update and peer-update assignments
drawn from $\pi_{\text{op}}$, and (vi)~optionally inserts semantic-core
assignments from the twelve hardcoded idiom templates.
The rendered program is then wrapped in a function signature with a
Frama-C \texttt{requires} clause and passed downstream for execution and
invariant generation.

\begin{figure}[htb]
\centering
\fbox{\parbox{0.92\columnwidth}{\small
\textbf{Algorithm: \textsc{LoopFactory} Generation}\\[2pt]
\textbf{Input:} Hyperparameters $\theta$, seed $s$\\
\textbf{Output:} A well-typed C function\\[2pt]
1: $\mathit{rng} \leftarrow \text{Random}(s)$\\
2: $\mathcal{P} \leftarrow \text{sample}(\text{candidates}, p,\; \mathit{rng})$
   \hfill\textit{// e.g.\ \{a,n\}}\\
3: $n_{\ell} \leftarrow \text{Uniform}[\min\_\text{fuel},\; \text{while\_fuel}]$
   \hfill\textit{// loop count}\\
4: Init block: for $v \in \mathcal{L}$, sample $e_v$ over $\mathcal{P}$ only\\
5: \textbf{for} $i = 1,\ldots,n_{\ell}$ \textbf{do}\\
6: \quad Allocate counter $\mathit{ctr}$, limit $\mathit{lim}$ via \texttt{NameAllocator}\\
7: \quad $\mathit{nla} \leftarrow \text{Bernoulli}(p_{\text{nonlinear}})$\\
8: \quad $(\text{inits},\; \text{guard},\; \text{step}) \leftarrow
   \texttt{SampleLoopControl}(\mathit{ctr},\mathit{lim},\mathit{nla})$\\
9: \quad Body $\leftarrow$ [step]\\
10:\quad \textbf{repeat} up to $k-1$ times:\\
11:\quad\quad Sample assign $\leftarrow \texttt{SemanticAssign}(\mathit{nla})$\\
12:\quad\quad Body $\leftarrow$ Body $\cup$ \{assign\}\\
13:\quad With prob.\ $p_{\text{semantic\_core}}$: inject one template idiom\\
14:\quad With prob.\ $q_{\text{nest}}$: recurse to depth $d{+}1 \le D_{\max}$\\
15:\quad Append \texttt{WhileLoop(guard, Body)} to forest\\
16:\textbf{end for}\\
17: \textbf{return} \texttt{Program}($\mathcal{P}$, inits, forest).render()
}}
\caption{\textsc{LoopFactory} generation algorithm.}
\label{alg:loop-factory}
\end{figure}

\subsection{Loop-Control Mode Sampling}

The function \texttt{SampleLoopControl} draws a loop-control mode from
seven shapes (Table~\ref{tab:loop-control}).
Weights differ between the NLA and linear families: multiplicative and
distance-to-limit modes are disabled for linear programs.

\begin{table}[htb]
\caption{Loop-control modes and their effect on counter, guard, and step.}
\label{tab:loop-control}
\centering\small
\begin{tabular}{@{}lll@{}}
\toprule
Mode & Guard shape & Step \\
\midrule
\texttt{inc1}      & $\mathit{ctr} < \mathit{lim}$ & $\mathit{ctr} \mathrel{+}= 1$ \\
\texttt{dec1}      & $\mathit{ctr} > 0$            & $\mathit{ctr} \mathrel{-}= 1$ \\
\texttt{inc\_step} & $\mathit{ctr} < \mathit{lim}$ & $\mathit{ctr} \mathrel{+}= d,\; d\in[2,5]$ \\
\texttt{dec\_step} & $\mathit{ctr} > d{-}1$        & $\mathit{ctr} \mathrel{-}= d$ \\
\texttt{mul\_up}   & $\mathit{ctr} < \mathit{lim}$ & $\mathit{ctr} \mathrel{*}= m,\; m\in\{2,3\}$ \\
\texttt{div\_down} & $\mathit{ctr} > 0$            & $\mathit{ctr} \mathrel{/}= 2$ \\
\texttt{dist\_to\_limit} & $\mathit{ctr} > \mathit{lim}$ & $\mathit{ctr} \mathrel{-}= d$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Concrete Generated Example}

The following function was generated by \textsc{LoopFactory} with
$\theta = (m{=}5,\; p{=}2,\; \text{while\_fuel}{=}2,\;
k{=}4,\; D_{\max}{=}1,\; p_{\text{nonlinear}}{=}0.55)$:

\begin{lstlisting}
/*@ requires a >= 0 && n >= 1; */
int f(int a, int n){
  int c, s, x;
  c=0; s=a; x=1;

  while (c < n) {      // inc1: ctr=c, lim=n
    c = c+1;
    s = s+c;           // semantic: cumulative sum
    x = x*c;           // NLA: factorial-style
  }

  while (x > 0) {      // div_down: ctr=x
    x = x/2;
  }
  /*@ assert s == a + n*(n+1)/2; */
}
\end{lstlisting}

This single program exercises: (i)~an NLA loop with invariants
$s = a + c(c+1)/2$ and $x = c!$; (ii)~a geometric-decay loop
requiring $x \ge 0$; (iii)~a postcondition that tests only the
sum invariant, so the \textsc{SAM2INV} pipeline must discover the
correct invariant by combining candidates from multiple LLM calls.

%% ============================================================
\section{Detailed Invariant Generation Algorithm}
\label{app:algorithm}
%% ============================================================

\subsection{Data Structures}

The pipeline maintains the following state for each outer loop index $i$:

\begin{itemize}
\item $\mathbf{record}_i$: the structured descriptor extracted from
  static analysis, containing the loop guard, assignments (transition
  relation), initial variable values, invariable (unmodified) parameters,
  and function parameter names.
\item $\mathcal{T}_i$: the execution trace set, a list of
  variable-state snapshots collected by the smart sampler.
\item $C_i$: the live candidate pool (a set of ACSL expression strings).
\item $C^*_i$: the certified invariant set (output).
\end{itemize}

\subsection{Complete Per-Loop Algorithm}

\begin{figure}[htb]
\centering
\fbox{\parbox{0.92\columnwidth}{\small
\textbf{Algorithm: InvariantGenerator per loop $i$}\\[2pt]
\textbf{Input:} Source code $P$, record $\mathbf{r}$, traces $\mathcal{T}$,
               LLM $\mathcal{M}$, verifier $\mathcal{V}$\\
\textbf{Output:} Annotated code $P^*$ or $\bot$\\[2pt]
\textit{Phase 1 — Generation:}\\
1: $P_{\text{tmpl}} \leftarrow \texttt{InsertTemplate}(P, i)$
   \hfill\textit{// PLACE\_HOLDER annotations}\\
2: $(\sigma, \ell) \leftarrow \texttt{PreparePrompt}(\mathbf{r}, \mathcal{T})$
   \hfill\textit{// (system, user) prompts}\\
3: \textbf{for} $j = 1,\ldots,N$ \textbf{in parallel} \textbf{do}\\
4: \quad $R_j \leftarrow \mathcal{M}(P_{\text{tmpl}}, \sigma, \ell,\;\tau_j)$
   \hfill\textit{// diverse temperature}\\
5: \quad $C_j \leftarrow \texttt{ExtractInvariants}(R_j)$\\
6: \textbf{end for}\\
7: $C \leftarrow \bigcup_j C_j$ \hfill\textit{// union of all candidates}\\[4pt]
\textit{Phase 2a — Heuristic ACSL Syntax Gate:}\\
8: $C \leftarrow \{c \in C \mid \texttt{SyntaxFilter}(c,\mathbf{r})= \text{pass}\}$\\[4pt]
\textit{Phase 2b — Execution-Trace Semantic Gate:}\\
9: $C \leftarrow \{c \in C \mid \forall \mathbf{s} \in \mathcal{T}:\;
   \texttt{eval}(c, \mathbf{s}) = \text{true}\}$\\[4pt]
\textit{Phase 2c — Conflict Detection:}\\
10: $C \leftarrow \texttt{RemoveConflicts}(C)$\\[4pt]
\textit{Phase 2d — Merge:}\\
11: $C_{\text{merged}} \leftarrow \texttt{Dedup}(C)$
    \hfill\textit{// whitespace-normalised}\\[4pt]
\textit{Phase 3 — Houdini Formal Pruning:}\\
12: $C^* \leftarrow \texttt{Houdini}(C_{\text{merged}}, \mathcal{V})$
    \hfill\textit{// see Algorithm~\ref{alg:houdini}}\\
13: \textbf{if} $C^* = \emptyset$ \textbf{then return} $\bot$\\[4pt]
\textit{Phase 4 — Postcondition Check \& Optional Repair:}\\
14: \textbf{if} $\mathcal{V}$ reports \texttt{assert} satisfied \textbf{then}\\
15: \quad \textbf{return} $\texttt{Annotate}(P, C^*)$\\
16: \textbf{else} run $\le K$ repair iterations (feed error to $\mathcal{M}$)\\
17: \textbf{return} $\texttt{Annotate}(P, C^*)$ or $\bot$
}}
\caption{Full per-loop invariant generation algorithm.}
\label{alg:full}
\end{figure}

\subsection{Role of Static Analysis}

Before Phase~1, the sampler's \texttt{LoopAnalysis} module performs a
\emph{lightweight static pre-pass} on the input C file to populate
$\mathbf{record}_i$.
This is \emph{not} symbolic execution in the strict sense; it is a
source-level analysis that:
\begin{enumerate}
\item Identifies the loop guard (transition relation) by reading
  the \texttt{condition} field recorded in the JSON analysis file
  produced by the Frama-C preprocessing step.
\item Extracts the set of variables that are never assigned inside
  the loop body (\emph{unchanged variables}), which become candidates
  for $\texttt{\textbackslash at}(v, \text{Pre})$ invariants.
\item Infers conservative integer bounds $[\ell_v, u_v]$ for each
  parameter via \texttt{LoopBoundAnalyzer}, which are used to
  constrain the smart sampler's input domain.
\item Builds the \textbf{record} structure that encodes loop content,
  transition expression, pre-condition, and the names of function
  parameters (needed to gate $\texttt{\textbackslash at}$ usage in the
  syntax filter).
\end{enumerate}
The Frama-C/WP oracle is \emph{only} invoked during the Houdini
pruning stage (Phase~3) and never during candidate generation or
lightweight filtering.

\subsection{Non-Attributability of the Certified Output}
\label{app:nonattrib}

We formalise the key structural property stated informally in
Section~\ref{sec:generation}.

\begin{definition}[Attribution]
Given $N$ candidate sets $C_1,\ldots,C_N$ and a certified output
$C^*$, we say $C^*$ is \emph{attributable to call $j$} if
$C^* \subseteq C_j$.
\end{definition}

\begin{proposition}[Non-attributability is typical]
\label{prop:nonattrib}
Suppose the correct annotation for a loop requires a conjunction of
$m \ge 2$ invariant clauses $c_1,\ldots,c_m$.
If each clause $c_i$ is discovered independently by each of the
$N$ calls with probability $q \in (0,1)$, then the probability that
\emph{all} clauses appear in any single call $C_j$ is $q^m$,
while the probability that all clauses appear in the union
$C_{\text{pool}} = \bigcup_j C_j$ is $1 - (1-q)^{mN}$.
For $q = 0.6$, $m = 4$, $N = 5$: single-call coverage $= 0.6^4 \approx 0.13$;
union coverage $= 1 - 0.4^{20} \approx 1.00$.
\end{proposition}

\begin{proof}
Follows directly from independence and the complement rule for
union of events.
\end{proof}

Proposition~\ref{prop:nonattrib} shows that the gap between
single-call and union coverage grows exponentially with the number
of required conjuncts $m$.
In practice, real loop invariants for arithmetic programs require
$m \in [2, 6]$ conjuncts (boundary invariants, postcondition
conjuncts, auxiliary equalities), making single-call attribution
unlikely in typical cases.

\begin{corollary}
Under the conditions of Proposition~\ref{prop:nonattrib} with
$m \ge 2$ and $q < 1$, the expected fraction of per-call outputs
$C_j$ for which $C^* \subseteq C_j$ is $q^m < 1$.
Assigning a positive reward to calls satisfying $C^* \subseteq C_j$
and a negative reward to others would on average penalise
$(1 - q^m) > 0$ fraction of calls that may have contributed
essential clauses to the union.
\end{corollary}

This corollary shows that any \emph{per-call} binary scoring scheme
--- including GRPO --- systematically mislabels calls that contribute
essential clauses to the final answer, degrading the training signal
for exactly the behaviours (diverse conjunct coverage) that make the
union effective.

%% ============================================================
\section{DPO Data Construction: Formal Specification}
\label{app:dpo}
%% ============================================================

\subsection{Chosen Response Construction}

Given a program $P$ and the certified invariant set $C^*$ for loop
$i$, the chosen annotated program is:
\[
P^+ = \texttt{Annotate}(P,\; i,\; C^*)
\]
where \texttt{Annotate} inserts the ACSL block
\begin{center}
\texttt{/*@ loop invariant $c_1$; \ldots loop invariant $c_k$;\\
\phantom{/*@} loop assigns \textit{vars}; */}
\end{center}
immediately before the \texttt{while} statement of loop $i$.
The $\texttt{loop assigns}$ clause is derived from the set of
variables assigned anywhere in the loop body.
$P^+$ is guaranteed to satisfy Frama-C/WP because it survived
Stage~3 (Houdini pruning); no additional verification is needed
for the training record.

\subsection{Rejected Response Construction and Stage Labelling}

For each $r \in C_{\text{pool}} \setminus C^*$, we construct:
\[
P^-_r = \texttt{Annotate}(P,\; i,\; \{r\})
\]
and record the stage $k(r) \in \{1, 2, 3\}$ at which $r$ was
eliminated:
\begin{itemize}
\item $k(r) = 1$: $r$ failed the ACSL syntax gate
  (Appendix~\ref{app:syntax-gate}).
\item $k(r) = 2$: $r$ passed syntax but was falsified by some
  trace state $\mathbf{s} \in \mathcal{T}$, i.e.\
  $\texttt{eval}(r, \mathbf{s}) = \text{false}$.
\item $k(r) = 3$: $r$ passed syntax and trace filters but was
  removed by Houdini because Frama-C/WP could not verify
  its establishment or preservation condition.
\end{itemize}
The full DPO training record for program $P$, loop $i$, and
rejected expression $r$ is the tuple:
\[
\mathcal{D}(P, i, r) = \bigl(P,\; P^+,\; P^-_r,\; k(r)\bigr).
\]

\subsection{Stage-Stratified Loss Weighting}

Standard DPO minimises the loss:
\[
\mathcal{L}_{\text{DPO}} =
  -\mathbb{E}\!\left[\log \sigma\!\left(
    \beta \log \frac{\pi_\theta(P^+ \mid P)}{\pi_{\text{ref}}(P^+ \mid P)}
    - \beta \log \frac{\pi_\theta(P^-_r \mid P)}{\pi_{\text{ref}}(P^-_r \mid P)}
  \right)\right].
\]
We extend this with stage-dependent weights $w_k$:
\[
\mathcal{L}_{\text{S-DPO}} =
  -\mathbb{E}\!\left[w_{k(r)} \cdot \log \sigma\!\left(
    \beta \log \frac{\pi_\theta(P^+ \mid P)}{\pi_{\text{ref}}(P^+ \mid P)}
    - \beta \log \frac{\pi_\theta(P^-_r \mid P)}{\pi_{\text{ref}}(P^-_r \mid P)}
  \right)\right].
\]
The rationale for $w_1 \le w_2 \le w_3$ is that Stage-3 rejections
are the hardest preference distinctions: the rejected expression is
consistent with all observed program states and was eliminated only
by a formal inductiveness check, making the margin between $P^+$ and
$P^-_r$ the smallest and the training signal the most informative.
Concretely, we use $w_1 = 0.5,\; w_2 = 1.0,\; w_3 = 2.0$ as
default weights, reflecting the increasing difficulty of the
corresponding rejection judgements.

\subsection{SFT Records}

Alongside DPO pairs, each successful pipeline run produces an SFT
record $(P,\; P^+)$.
SFT pre-training warms up the model towards the format and style
of ACSL annotations before DPO alignment, following the standard
two-phase fine-tuning recipe~\cite{ouyang2022training}.
Because $P^+$ is formally verified, SFT on these records teaches
the model what a \emph{correct and informative} annotation looks
like, providing a positive learning signal that complements the
contrastive DPO signal.

%% ============================================================
\section{Prompts Used in Each Stage}
\label{app:prompts}
%% ============================================================

\subsection{System Prompt}

The system prompt is loaded verbatim from \texttt{prompts/system\_prompt.txt}
and prepended to every LLM call. Its full content is reproduced below.

\begin{lstlisting}[style=coqstyle, basicstyle=\ttfamily\scriptsize]
You are a formal verification expert specializing in loop
invariant synthesis for Frama-C with the WP plugin.

## TASK
Given a C function with a loop and a postcondition
(/*@ assert ... */), generate ACSL loop annotations
(invariants, assigns) that enable Frama-C/WP to verify
the assertion.

## CORE STRATEGY: Assertion-Driven Invariant Synthesis
1. Decompose the assertion: each conjunct of the assert
   (split on &&) is a candidate loop invariant.
2. Add boundary invariants: weaken the loop guard.
   - while(i < n) needs: i <= n
   - while(n <= a) needs: n <= a+1
3. Preserve parameter values: if a parameter is unmodified,
   assert: loop invariant x == \at(x, Pre);
4. Verify sufficiency: check that (invariants AND NOT guard)
   implies the postcondition.

## FORBIDDEN CONSTRUCTS
- \forall, \exists  (quantifiers not supported)
- predicate, logic, axiomatic, lemma
- Ternary ? :
- \at(local_var, Pre)  (\at only on function parameters)
- ^ for exponentiation  (write x*x*x for x cubed)

## ALLOWED OPERATORS
Comparison: ==, !=, <, <=, >, >=
Logical:    &&, ||, !, ==>, <==>
Arithmetic: +, -, *, /, %

## OUTPUT
Return ONLY the annotated C function. Do not include
explanations.
\end{lstlisting}

\subsection{User Prompt (Loop Context Block)}

The user prompt is assembled by \texttt{PromptFormatter} and passed
as the second message in the conversation.
It consists of two parts.

\paragraph{Part 1 — Loop context.}
\begin{lstlisting}[style=coqstyle, basicstyle=\ttfamily\scriptsize]
### Loop Context: ###

1. Loop Context
  A. Pre-Condition (Before Loop Entry): `<precondition>`
  B. Loop Transition Relation: `<transition_expr>`
  C. Loop Snippet:
```c
<loop_code>
```

2. Execution Traces
   Each trace shows the full sequence of conditional
   evaluations, step by step.

   WARNING: CRITICAL TEMPORAL SEMANTICS:
   - Each state is labeled as
     'BEFORE loop body execution' or 'AFTER loop terminates'
   - Loop invariants must hold at the START of each iteration
     (BEFORE body executes)
   ...
\end{lstlisting}

\paragraph{Part 2 — Execution traces.}
For each sampled input group (up to $G{=}5$), the formatter emits
a trace block:
\begin{lstlisting}[style=coqstyle, basicstyle=\ttfamily\scriptsize]
[TRACE 1]
    [ n==0 && x==0 && y==1 && z==6 ]
        (BEFORE loop starts) ->
    [ n==1 && x==1 && y==7 && z==12 ]
        (BEFORE iteration 1 body executes) ->
    [ n==2 && x==8 && y==25 && z==18 ]
        (AFTER loop terminates)
\end{lstlisting}

The temporal labels (\texttt{BEFORE iteration $k$ body executes})
are essential: they tell the LLM that an invariant must hold at loop
entry of each iteration, not at loop exit, which is a common source
of error in naive prompting.
Initial values use $\texttt{\textbackslash at}(v, \text{Pre})$ notation
so the model can directly reference them in \texttt{loop invariant} lines.

\paragraph{Diversity via temperature.}
Each of the $N$ parallel LLM calls uses an independently sampled
temperature $\tau_j$.
In the default configuration, the primary call uses $\tau_1 = 1.0$ and
subsequent calls are drawn uniformly from $\{0.8, 1.0, 1.1, 1.2\}$,
ensuring that the candidate pool covers both conservative and more
exploratory invariant conjectures.

%% ============================================================
\section{Heuristic ACSL Syntax Gate: Implementation Details}
\label{app:syntax-gate}
%% ============================================================

The syntax gate (Stage~1, Section~\ref{sec:filtering}) runs before
any program execution or Frama-C invocation.
It is implemented in \texttt{unified\_filter.py} as a rule-based
checker that operates directly on ACSL expression strings.

\subsection{Rejection Rules}

Each candidate invariant expression is checked against
the following ordered rules (any single failure causes rejection):

\begin{enumerate}

\item \textbf{Trivial/placeholder tokens.}
  Expressions equal to \texttt{true}, \texttt{false}, \texttt{...},
  or containing only punctuation are rejected immediately.

\item \textbf{Non-printable or non-ASCII characters.}
  Frama-C requires printable ASCII (U+0020--U+007E).
  Characters such as the Unicode inequality signs \textsf{$\leq$}, \textsf{$\geq$},
  \textsf{$\neq$}, or control characters (e.g.\ BEL, U+0007 occasionally
  emitted by LLMs) cause rejection.
  The error message instructs the model to use \texttt{<=}, \texttt{!=}.

\item \textbf{Nested \texttt{loop invariant} keyword.}
  When a LLM fills in a \texttt{PLACE\_HOLDER} slot with a complete
  \texttt{loop invariant expr;} line instead of a bare expression,
  Frama-C cannot parse the annotation and enters a pathological parsing
  state.
  A regex check (\texttt{/\textbackslash bloop\textbackslash sinvariant\textbackslash b/i})
  catches and rejects these.

\item \textbf{Bracket balance.}
  Unmatched parentheses, square brackets, or braces are rejected,
  with the position of the first mismatch reported in the error message.

\item \textbf{Forbidden quantifiers.}
  Presence of \texttt{\textbackslash forall} or \texttt{\textbackslash exists}
  triggers rejection; Frama-C/WP does not support quantifiers in
  loop invariant annotations.

\item \textbf{Forbidden ACSL definitions.}
  The keywords \texttt{predicate}, \texttt{inductive}, \texttt{logic},
  \texttt{axiomatic}, \texttt{lemma} may not appear in invariant expressions.

\item \textbf{Forbidden ACSL math operators.}
  \texttt{\textbackslash product}, \texttt{\textbackslash sum},
  \texttt{\textbackslash min}, \texttt{\textbackslash max} are rejected
  (not supported by the WP plugin for loop invariants).

\item \textbf{Ternary operator.}
  The \texttt{?\ :} construct is not valid ACSL.

\item \textbf{Undefined variable names.}
  Each identifier in the expression is compared against
  $\mathit{known\_vars}$, the union of local variables, parameters,
  and ACSL built-ins extracted from $\mathbf{record}$.
  Unknown identifiers are rejected with a diagnostic listing the
  candidates.

\item \textbf{\texttt{\textbackslash at} scope check.}
  Expressions of the form $\texttt{\textbackslash at}(v, \text{Pre})$
  are permitted only when $v \in \mathcal{P}$ (function parameters).
  Usage on local variables is rejected, since local variables have no
  pre-state binding in Frama-C/WP.

\item \textbf{Exponentiation (\texttt{\^{}} or \texttt{\textbackslash pow}).}
  A final safety sweep removes any surviving candidates containing
  these tokens, which represent bitwise XOR or undefined ACSL
  functions respectively.

\end{enumerate}

\subsection{Post-Merge Sanitisation}

After the union of $N$ candidate pools is formed (Algorithm~\ref{alg:full},
line~11), an additional normalisation pass is applied:
\begin{itemize}
\item \texttt{\textbackslash at}($v$, Pre) for local variable $v$ is
  rewritten to plain $v$ (conservative safe fallback).
\item Any invariant re-introducing \texttt{\^{}} or \texttt{\textbackslash pow}
  is silently dropped.
\end{itemize}
This sanitisation step prevents the Houdini stage from encountering
annotation parse errors that would stall the Frama-C subprocess.

%% ============================================================
\section{Smart Dynamic Sampling: Implementation Details}
\label{app:sampling}
%% ============================================================

\subsection{Overview}

The smart sampler (\texttt{smart\_sampler.py}) generates concrete
integer inputs for the program's function parameters.
Its design goal is to produce a small but informationally dense set
of execution traces that expose the polynomial relationships maintained
by the loop, while avoiding:
\begin{itemize}
\item All-zero inputs (which collapse polynomial terms and prevent
  coefficient identification).
\item Excessively large inputs (which cause integer overflow or
  time-outs during dynamic execution).
\end{itemize}

\subsection{Tiered Value Generation}

For each parameter $v$ with domain $[\ell_v, u_v]$ inferred by
\texttt{LoopBoundAnalyzer}, the sampler constructs four tiers:
\begin{align*}
\mathcal{T}_0(v) &= \{0, 1, -1\} \cap [\ell_v, u_v]
  && \text{(special corner values)} \\
\mathcal{T}_1(v) &= \{2,\ldots,10\} \cap [\ell_v, u_v]
  && \text{(small positive integers)} \\
\mathcal{T}_{1'}(v) &= \{-2,\ldots,-10\} \cap [\ell_v, u_v]
  && \text{(small negatives, if enabled)} \\
\mathcal{T}_2(v) &\subseteq \{11,\ldots,50\}
  && \text{(5 randomly drawn medium values)} \\
\mathcal{T}_3(v) &\subseteq \{51,\ldots,100\}
  && \text{(3 randomly drawn large values)}
\end{align*}

\subsection{Phased Cartesian Sampling}

Inputs are generated in four phases.
Each phase fills part of the quota of at most $S_{\max}$
samples (default $S_{\max} = 20$).
Already-seen input tuples are deduplicated via a hash set.

\begin{enumerate}
\item \textbf{Phase~1 (corner cases).}
  Generate all tuples in $\prod_v \mathcal{T}_0(v)$.
  For $p$ parameters each with up to 3 special values, this produces
  at most $3^p$ tuples (e.g.\ 9 for $p=2$).
  These inputs are ideal for fitting degree-0 and degree-1
  polynomial terms.

\item \textbf{Phase~2 (mixed tier 0+1).}
  Enumerate combinations where each coordinate is drawn from
  $\mathcal{T}_0(v) \cup \mathcal{T}_1(v)$.
  Combinations are ordered by total tier index
  $\sum_v \text{tier}(v_j)$, so simpler combinations are generated
  first.

\item \textbf{Phase~3 (all tiers).}
  Extend to include $\mathcal{T}_2$ and $\mathcal{T}_3$,
  again prioritised by total tier index.
  This covers medium-range inputs needed to disambiguate
  quadratic from linear relationships.

\item \textbf{Phase~4 (biased random fill).}
  If the quota is not yet reached, fill with random tuples
  where each coordinate is drawn with probability 0.8 from
  $[0, 20]$ and 0.2 from $[21, 100]$.
  This phase ensures coverage of edge cases not reached
  by the structured phases.
\end{enumerate}

\subsection{Trace Collection and Formatting}

Each accepted input tuple is passed to
\texttt{DynamicExecutorConfigurable}, which instruments the C source
with \texttt{printf} statements recording all variable values at the
top of each loop iteration.
The collected trace for a single input is a sequence of
variable-assignment strings (e.g.
\texttt{(n == 2) * (x == 8) * (y == 25) * (z == 18)}).
These are parsed and formatted by \texttt{PromptFormatter}
into the temporal-labelled trace blocks shown in
Appendix~\ref{app:prompts}.

To prevent context-window overflow, the formatter applies two
limits:
\begin{itemize}
\item At most $G = 5$ trace groups are included per LLM call.
\item Within each group, at most $k_{\max} = 10$ iteration
  snapshots are kept; if a loop runs for more than $k_{\max}$
  iterations, the first $\lfloor k_{\max}/2 \rfloor$ and last
  $\lceil k_{\max}/2 \rceil$ snapshots are retained, and the
  truncation is noted explicitly in the prompt.
\end{itemize}
These limits ensure that the total prompt length stays within
the LLM's context window even for programs with deeply nested
loops or large parameter ranges.
